{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import string\n",
    "\n",
    "x_train = np.genfromtxt('processed_train.txt', delimiter=',')\n",
    "x_train = np.delete(x_train,-1,axis = 1)\n",
    "x_test = np.genfromtxt('processed_test.txt', delimiter=',')\n",
    "x_test = np.delete(x_test,-1,axis = 1)\n",
    "with open('../data/train_labels.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=\",\")\n",
    "    label_train = list(reader)   \n",
    "del label_train[0]\n",
    "label_train = np.asarray(label_train)[:,1]\n",
    "label_train = label_train.tolist()\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('../data/train_labels.csv')\n",
    "obj_df = df.select_dtypes(include=['object']).copy()\n",
    "obj_df.head()\n",
    "\n",
    "lb_class = LabelEncoder()\n",
    "obj_df['Category_code']=lb_class.fit_transform(obj_df['Category'])\n",
    "obj_df[['Category','Category_code']]\n",
    "y_train = np.asarray(obj_df)[:,1]\n",
    "y_train = y_train.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    result = []\n",
    "    for i in a:\n",
    "        result.append(np.exp(i)/sum(np.exp(i)))\n",
    "    result = np.asarray(result)\n",
    "    return result\n",
    "\n",
    "def modelbuiler(n_layer, dim_layer, itera):\n",
    "    x=[]\n",
    "    x = np.concatenate((np.zeros((1,n_sample)),x_in.T),axis = 0)\n",
    "    W = []\n",
    "    W.append(np.random.randn(dim_layer+1,n_feature+1))\n",
    "    if n_layer >=3:\n",
    "        for i in range(1,n_layer-1):\n",
    "            W.append(np.random.randn(dim_layer+1,dim_layer+1))\n",
    "    W.append(np.random.randn(n_class,dim_layer+1))\n",
    "    model = {}\n",
    "    t = np.zeros((n_class,n_sample))\n",
    "    for i in range(0,n_sample):\n",
    "        t[y_in[i],i] = 1\n",
    "    \n",
    "    for iteration in range(0,itera):\n",
    "        #Forward Prop\n",
    "        a=[]\n",
    "        z=[]\n",
    "        a.append(np.dot(W[0],x))\n",
    "        z.append(np.tanh(a[0]))\n",
    "        z[0][0]=np.ones_like(z[0][0])\n",
    "        if n_layer >=3:\n",
    "            for i in range(1,n_layer-1):\n",
    "                a.append(np.dot(W[i],z[i-1]))\n",
    "                z.append(np.tanh(a[i]))\n",
    "                z[i][0]=np.ones_like(z[i][0])\n",
    "        a.append(np.dot(W[-1],z[-1]))\n",
    "        z.append(softmax(a[-1]))        \n",
    "        \n",
    "        #Back Prop Gradient Descent\n",
    "        delta = []\n",
    "        dW=[]\n",
    "        h_prime = []\n",
    "        for i in z:\n",
    "            h_prime.append(np.ones_like(i)-np.multiply(i,i))\n",
    "        delta.append(z[-1]-t)\n",
    "        dW.append(np.dot(delta[0],z[1].T))\n",
    "        if n_layer >= 3:\n",
    "            for i in range(1,n_layer-1):\n",
    "                delta.append(np.multiply(h_prime[-1-i],np.dot(W[-i].T,delta[-1])))\n",
    "                dW.append(np.dot(delta[-1],z[-i-2].T))\n",
    "        delta.append(np.multiply(h_prime[0],np.dot(W[1].T,delta[-1])))\n",
    "        dW.append(np.dot(delta[-1],x.T))\n",
    "        \n",
    "        for i in range(0,len(W)):\n",
    "            W[i]+=-epsilon*dW[-i-1]\n",
    "        \n",
    "    model={'W':W}\n",
    "    return model\n",
    "\n",
    "#Estimate x\n",
    "def guess(model, x_guess):\n",
    "    W = model['W']\n",
    "    x=[]\n",
    "    x = np.concatenate((np.zeros((1,n_sample)),x_guess.T),axis = 0)\n",
    "    a=[]\n",
    "    z=[]\n",
    "    a.append(np.dot(W[0],x))\n",
    "    z.append(np.tanh(a[0]))\n",
    "    z[0][0]=np.ones_like(z[0][0])\n",
    "    if layer_number >=3:\n",
    "        for i in range(1,layer_number-1):\n",
    "            a.append(np.dot(W[i],z[i-1]))\n",
    "            z.append(np.tanh(a[i]))\n",
    "            z[i][0]=np.ones_like(z[i][0])\n",
    "    a.append(np.dot(W[-1],z[-1]))\n",
    "    z.append(softmax(a[-1]))\n",
    "    return z[-1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4831.]]]\n",
      "3\n",
      "nan\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      1.00      0.07       169\n",
      "           1       0.00      0.00      0.00       160\n",
      "           2       0.00      0.00      0.00       229\n",
      "           3       0.00      0.00      0.00       287\n",
      "           4       0.00      0.00      0.00       196\n",
      "           5       0.00      0.00      0.00       202\n",
      "           6       0.00      0.00      0.00       113\n",
      "           7       0.00      0.00      0.00       236\n",
      "           8       0.00      0.00      0.00       139\n",
      "           9       0.00      0.00      0.00       110\n",
      "          10       0.00      0.00      0.00        92\n",
      "          11       0.00      0.00      0.00       102\n",
      "          12       0.00      0.00      0.00       106\n",
      "          13       0.00      0.00      0.00       129\n",
      "          14       0.00      0.00      0.00       163\n",
      "          15       0.00      0.00      0.00       138\n",
      "          16       0.00      0.00      0.00       255\n",
      "          17       0.00      0.00      0.00       250\n",
      "          18       0.00      0.00      0.00       193\n",
      "          19       0.00      0.00      0.00       108\n",
      "          20       0.00      0.00      0.00       201\n",
      "          21       0.00      0.00      0.00       140\n",
      "          22       0.00      0.00      0.00       208\n",
      "          23       0.00      0.00      0.00       177\n",
      "          24       0.00      0.00      0.00        91\n",
      "          25       0.00      0.00      0.00       140\n",
      "          26       0.00      0.00      0.00       135\n",
      "          27       0.00      0.00      0.00       210\n",
      "          28       0.00      0.00      0.00       144\n",
      "          29       0.00      0.00      0.00        85\n",
      "          30       0.00      0.00      0.00        92\n",
      "\n",
      "   micro avg       0.03      0.03      0.03      5000\n",
      "   macro avg       0.00      0.03      0.00      5000\n",
      "weighted avg       0.00      0.03      0.00      5000\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "x_in = x_train[0:5000]\n",
    "y_in = y_train[0:5000]\n",
    "x_try = x_train[5000:10000]\n",
    "y_try = y_train[5000:10000]\n",
    "\n",
    "n_sample = x_in.shape[0]\n",
    "n_feature = x_in.shape[1]\n",
    "n_class = 31\n",
    "\n",
    "#Utilize NN Cross Validation\n",
    "itera = 300\n",
    "epsilon_valid = [0.01]\n",
    "layer_number_valid = [3]\n",
    "layer_dimension_valid = [500]\n",
    "error = np.zeros((len(epsilon_valid),len(layer_number_valid),len(layer_dimension_valid)))\n",
    "for i,epsilon in enumerate(epsilon_valid):\n",
    "    for j,layer_number in enumerate(layer_number_valid):\n",
    "        for k,layer_dimension in enumerate(layer_dimension_valid):\n",
    "            model = modelbuiler(layer_number,layer_dimension, itera)\n",
    "            y_prob = guess(model, x_try)\n",
    "            result = np.argmax(y_prob,0)\n",
    "            diff = y_try-result\n",
    "            diff = diff.astype(bool).astype(int)\n",
    "            error[i,j,k] = sum(diff)\n",
    "            print(error)\n",
    "            \n",
    "min_error = []\n",
    "min_error_loc = []\n",
    "for i in error:\n",
    "    for j in i:\n",
    "        min_error.append(min(j))\n",
    "for i in np.where(error==min(min_error)):\n",
    "    min_error_loc.append(i[0])\n",
    "epsilon = epsilon_valid[min_error_loc[0]]\n",
    "layer_number = layer_number_valid[min_error_loc[1]]\n",
    "layer_dimension = layer_dimension_valid[min_error_loc[2]]\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = y_try\n",
    "print(layer_number)\n",
    "model = modelbuiler(layer_number,layer_dimension, itera)\n",
    "y_prob = guess(model, x_try)\n",
    "print(max(y_prob[0]))\n",
    "result = np.argmax(y_prob,0)\n",
    "print(classification_report(y_try, result))\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
